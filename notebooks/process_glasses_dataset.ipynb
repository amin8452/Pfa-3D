{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Glasses Dataset with Hunyuan3D-2\n",
    "\n",
    "This notebook demonstrates how to process a dataset of glasses images and generate 3D models using the adapted Hunyuan3D-2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up the environment and clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/amin8452/Pfa-3D.git\n",
    "%cd Pfa-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision\n",
    "!pip install trimesh numpy scipy matplotlib opencv-python pyyaml tqdm tensorboard plotly requests\n",
    "!pip install safetensors\n",
    "\n",
    "# Install PyTorch3D (this can be complex, so we use a pre-built version for Colab)\n",
    "import sys\n",
    "import torch\n",
    "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "version_str=\"\".join([\n",
    "    f\"py3{sys.version_info.minor}_cu\",\n",
    "    torch.version.cuda.replace(\".\",\"\"),\n",
    "    f\"_pyt{pyt_version_str}\"\n",
    "])\n",
    "!pip install fvcore iopath\n",
    "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Adapt the Hunyuan3D-2 Model\n",
    "\n",
    "Now, let's download and adapt the Hunyuan3D-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone the Hunyuan3D-2 repository\n",
    "!python scripts/download_pretrained.py --model repo\n",
    "\n",
    "# Download pre-trained models from Hugging Face\n",
    "!python scripts/download_pretrained.py --model all\n",
    "\n",
    "# Adapt the model for glasses reconstruction\n",
    "# Note: Use the correct directory name where the repository was cloned\n",
    "!python scripts/adapt_hunyuan_model.py --hunyuan_dir Hunyuan3D-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Your Dataset\n",
    "\n",
    "Now, let's upload your dataset of glasses images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create data directory\n",
    "!mkdir -p data/glasses/images\n",
    "\n",
    "# Upload images\n",
    "from google.colab import files\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Option 1: Upload a zip file containing all images\n",
    "print(\"Please upload a zip file containing your glasses images...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the zip file\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('data/glasses')\n",
    "        print(f\"Extracted {filename} to data/glasses\")\n",
    "    else:\n",
    "        # If it's not a zip file, assume it's an image and save it\n",
    "        with open(os.path.join('data/glasses/images', filename), 'wb') as f:\n",
    "            f.write(uploaded[filename])\n",
    "        print(f\"Saved {filename} to data/glasses/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Option 2: Upload individual images\n",
    "# You can run this cell multiple times to upload more images\n",
    "print(\"Please upload individual glasses images...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename, content in uploaded.items():\n",
    "    with open(os.path.join('data/glasses/images', filename), 'wb') as f:\n",
    "        f.write(content)\n",
    "    print(f\"Saved {filename} to data/glasses/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Dataset\n",
    "\n",
    "Let's check the dataset to make sure it's properly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = 'data/glasses'\n",
    "\n",
    "# Find all image files\n",
    "image_files = []\n",
    "for root, _, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp')):\n",
    "            image_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Found {len(image_files)} images in {dataset_path}\")\n",
    "\n",
    "# Display a few sample images\n",
    "if image_files:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, image_path in enumerate(image_files[:5]):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        img = Image.open(image_path)\n",
    "        plt.imshow(np.array(img))\n",
    "        plt.title(os.path.basename(image_path))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Dataset\n",
    "\n",
    "Now, let's process the dataset and generate 3D models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process the dataset\n",
    "!python scripts/process_dataset.py --dataset_path data/glasses --output_dir results/meshes --checkpoint checkpoints/hunyuan3d_base.safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Results\n",
    "\n",
    "Let's visualize some of the generated 3D models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Path to the generated meshes\n",
    "meshes_dir = 'results/meshes'\n",
    "\n",
    "# Find all mesh files\n",
    "mesh_files = [f for f in os.listdir(meshes_dir) if f.endswith('.obj')]\n",
    "\n",
    "print(f\"Found {len(mesh_files)} meshes in {meshes_dir}\")\n",
    "\n",
    "# Display a few sample meshes\n",
    "if mesh_files:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, mesh_file in enumerate(mesh_files[:3]):\n",
    "        mesh_path = os.path.join(meshes_dir, mesh_file)\n",
    "        mesh = trimesh.load(mesh_path)\n",
    "        \n",
    "        # Get the vertices\n",
    "        vertices = np.array(mesh.vertices)\n",
    "        \n",
    "        # Create a 3D plot\n",
    "        ax = plt.subplot(1, 3, i+1, projection='3d')\n",
    "        ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], s=1)\n",
    "        ax.set_title(mesh_file)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Set equal aspect ratio\n",
    "        max_range = np.max([\n",
    "            np.ptp(vertices[:, 0]),\n",
    "            np.ptp(vertices[:, 1]),\n",
    "            np.ptp(vertices[:, 2])\n",
    "        ])\n",
    "        mid_x = np.mean([np.min(vertices[:, 0]), np.max(vertices[:, 0])])\n",
    "        mid_y = np.mean([np.min(vertices[:, 1]), np.max(vertices[:, 1])])\n",
    "        mid_z = np.mean([np.min(vertices[:, 2]), np.max(vertices[:, 2])])\n",
    "        ax.set_xlim(mid_x - max_range/2, mid_x + max_range/2)\n",
    "        ax.set_ylim(mid_y - max_range/2, mid_y + max_range/2)\n",
    "        ax.set_zlim(mid_z - max_range/2, mid_z + max_range/2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Results\n",
    "\n",
    "Finally, let's download the generated 3D models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compress the results into a zip file\n",
    "!zip -r results.zip results/meshes\n",
    "\n",
    "# Download the zip file\n",
    "from google.colab import files\n",
    "files.download('results.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
